{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "Logistic regression is a classification model that is very easy to implement but performs very well on linearly separable classes. Logistic regression is a linear model for binary classification but can be extended to multiclass classification - OvR or multiple units methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic Regression Model\n",
    "\n",
    "Let $\\mathbf{x}$ be input features and $\\mathbf{w}$ and $b$ corresponding weight vector and bias:\n",
    "\n",
    "$\\mathbf{x}\\in\\mathbb{R}^n\\,\\,, \\mathbf{w}\\in\\mathbb{R}^n\\,\\,, b\\in\\mathbf{R}$\n",
    "\n",
    "\n",
    "Logistic regression outputs\n",
    "\n",
    "$\\sigma(z)=\\dfrac{1}{1+e^{-z}},\\,\\,$  where $z=\\mathbf{w}^T \\mathbf{x}+b$\n",
    "\n",
    "The output of the sigmoid function $\\sigma(z)$ can be interpreted as the probability of a given sample belonging to the positive class.\n",
    "\n",
    "$\\sigma(z)=P(y=1|\\mathbf{x};\\mathbf{w})$\n",
    "\n",
    "The predicted probability can then be converted into a binary outcome via a threshold function:\n",
    "\n",
    "\n",
    "$\\hat{y}=\\left\\{ \\begin{array}{} 1\\, if\\, \\sigma(z) \\geq 0.5 \\\\ 0\\, otherwise\\end{array} \\right.$\n",
    "\n",
    "\n",
    "Or the equivalent:\n",
    "\n",
    "$\\hat{y}=\\left\\{ \\begin{array}{} 1\\, if\\, z \\geq 0.0 \\\\ 0\\, otherwise\\end{array} \\right.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb288ca01d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "z = np.arange(-7, 7, 0.1)\n",
    "phi_z = sigmoid(z)\n",
    "\n",
    "plt.plot(z, phi_z)\n",
    "plt.axvline(0.0, color='k')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\sigma (z)$')\n",
    "\n",
    "# y axis ticks and gridline\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "ax = plt.gca()\n",
    "ax.yaxis.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression training\n",
    "\n",
    "The logistic regression model is trained using gradient descent by  minimizing the cost function $J(\\mathbf{\\Theta})$ w.r.t. $\\mathbf{\\Theta},\\,\\,$ where $\\mathbf{\\Theta}=\\{\\mathbf{w};\\,b\\}$\n",
    "\n",
    "Let \n",
    "\n",
    "$\\mathbf{X}=\\{\\mathbf{x}^{(1)},...,\\mathbf{x}^{(m)}\\}$, where $\\mathbf{x}\\in\\mathbb{R}^n$ \n",
    "\n",
    "$\\mathbf{Y}=\\{y^{(1)},...,y^{(m)}\\}$, where $y\\in\\{0,1\\}$ \n",
    "\n",
    "be a training dataset. \n",
    "\n",
    "The likelihood is defined as:\n",
    "\n",
    "$P(\\mathbf{Y}|\\mathbf{X};\\mathbf{\\Theta})$\n",
    "\n",
    "If the observations are independent and identically distributed then:\n",
    "\n",
    "$P(\\mathbf{Y}|\\mathbf{X};\\mathbf{\\Theta})=\\prod_{i=1}^m P(y^{(i)}|\\mathbf{x}^{(i)};\\mathbf{\\Theta})=\\prod_{i=1}^m (\\sigma(z^{(i)}))^{y^{(i)}} (1-\\sigma(z^{(i)}))^{1-y^{(i)}}$\n",
    "\n",
    "For numerical stability when calculating gradients it is better to optimize the (natural) log of this equation. So the final optimization objective is to minimize the cost function defined as negative log-likelihood, also referred to as binary cross-entropy.\n",
    "\n",
    "$\\mathbf{\\Theta_{ML}} = \\underset{\\mathbf{\\Theta}}\\arg\\min\\, J(\\mathbf{\\Theta})=\\underset{\\mathbf{\\Theta}}\\arg\\min\\, \\sum_{i=1}^m -y^{(i)}\\log(\\sigma(z^{(i)}))-(1-y^{(i)})\\log(1-\\sigma(z^{(i)}))$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Logistic regression training\n",
    "\n",
    "\n",
    "The cost function can be minimized using gradient descent. \n",
    "\n",
    "$\\mathbf{\\Theta}\\leftarrow\\mathbf{\\Theta}-\\eta\\nabla_{\\mathbf{\\Theta}}J(\\mathbf{\\Theta})\\,\\,$ where $\\nabla_{\\mathbf{\\Theta}}J(\\mathbf{\\Theta})$ is a gradient of the cost function w.r.t $\\mathbf{\\Theta}$ and $\\eta$ is a learning rate.\n",
    "\n",
    "Let $L(\\mathbf{x}^{(i)}, y^{(i)}, \\mathbf{w})=-y^{(i)}\\log(\\sigma(z^{(i)}))-(1-y^{(i)})\\log(1-\\sigma(z^{(i)}))$ be a per-example loss. Then:\n",
    "\n",
    "\n",
    "$\\nabla_{\\mathbf{\\Theta}}J(\\mathbf{\\Theta})=\\frac{1}{m}\\sum_{i=1}^m \\nabla_{\\mathbf{\\Theta}} L(\\mathbf{x}^{(i)}, y^{(i)}, \\mathbf{\\Theta})=\\frac{1}{m}\\sum_{i=1}^m \\nabla L^{(i)}(\\mathbf{\\Theta})=\\frac{1}{m}\\sum_{i=1}^m \\nabla L^{(i)}(\\mathbf{w},b)$ \n",
    "\n",
    "\n",
    "\n",
    "$\\nabla L^{(i)}(\\mathbf w, b)=\\begin{bmatrix} \\dfrac{\\partial{L^{(i)}(\\mathbf{w},b)}}{\\partial w_1} \\\\ \\vdots \\\\ \\dfrac{\\partial{L^{(i)}(\\mathbf{w},b)}}{\\partial w_n} \\\\ \\dfrac{\\partial L^{(i)}(\\mathbf{w},b)}{\\partial b} \\end{bmatrix} $\n",
    "\n",
    "To calculate partial derivates you can apply the chain rule:\n",
    "\n",
    "Let $a^{(i)}=\\sigma( z^{(i)})$\n",
    "\n",
    "$\\dfrac{\\partial L^{(i)}}{\\partial w_j}=\\dfrac{\\partial L^{(i)}}{\\partial a^{(i)}} \\dfrac{\\partial a^{(i)}}{\\partial z^{(i)}} \\dfrac{\\partial z^{(i)}}{\\partial w_{j}}$\n",
    "\n",
    "$\\dfrac{\\partial L^{(i)}}{\\partial a}=-\\dfrac{y^{(i)}}{a^{(i)}}+\\dfrac{1-y^{(i)}}{1-a^{(i)}},\\,\\,\\,\\,\n",
    "\\dfrac{\\partial a^{(i)}}{\\partial z^{(i)}}=a^{(i)}(1-a^{(i)}),\\,\\,\\,\\,\\,\n",
    "\\dfrac{\\partial z^{(i)}}{\\partial w_j}= x_j^{(i)},\\,\\,\\,\\,\n",
    "\\dfrac{\\partial z^{(i)}}{\\partial b}= 1$\n",
    "\n",
    "Which yields\n",
    "\n",
    "$\\dfrac{\\partial L^{(i)}}{\\partial w_j}=(a^{(i)}-y^{(i)})x_j^{(i)},\\,\\,\\,\n",
    "\\dfrac{\\partial L^{(i)}}{\\partial b}=a^{(i)}-y^{(i)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
