{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning Primer\n",
    "\n",
    "__Sources:__\n",
    "\n",
    "-  Kevin P. Murphy (2012). Machine Learning. A Probabilistic Perspective.\n",
    "-  Christopher Bishop (2006). Pattern Recognition and Machine Learning.\n",
    "-  Yaser Abu-Mostafa et al. (2012). Learning From Data.\n",
    "-  Trevor Hastie et al. (2008). The Elements of Statistical Learning.\n",
    "-  Tom M. Mitchell (1997). Machine Learning\n",
    "-  Ian Goodfellow, Yoshoua Bengio, Aaron Courville (2016). Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "*\"Machine learning is a set of methods that can automatically detect patterns in data, and then use the uncovered patterns to predict future data, or peform other kinds of decision making under uncertainty\"* __(Kevin P. Murphy).__\n",
    "\n",
    "*\"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E\"* __(Tom M. Mitchell).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of machine learning\n",
    "-  Supervised learning\n",
    "-  Unsupervised learning\n",
    "-  Semi-supervised learning\n",
    "-  Reinforcement learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised learning\n",
    "\n",
    "Learning a mapping from inputs $\\mathbf{x}$ to outputs $\\mathbf{y}$, given a labeled set of input-output pairs $\\mathcal{D}=\\{(\\mathbf{x_i},\\mathbf{y_i})\\}_{i=1}^N$.\n",
    "\n",
    "$\\mathcal{D}$ is called the __training set__, where $N$ is the number of training examples.\n",
    "\n",
    "In the simplest setting, each $\\mathbf{x_i}$ is a vector of numbers. In general, $\\mathbf{x_i}$ could be a complex structured object, such as an image or sentence. Components of $\\mathbf{x_i}$ are referred to as __features__, __attributes__, or __covariates__.\n",
    "\n",
    "The output $\\mathbf{y_i}$, often referred to as response variable, can in principle be anything, but most methods assume that $\\mathbf{y_i}$ is a __categorical__ or __nominal__ variable from some finite set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised learning as function approximation\n",
    "\n",
    "From one point of view, supervised learning can be considered  __function approximation__.\n",
    "\n",
    "Let's assume $y=f(x)$ to be some unknown function that generates our training data. The goal of learning is to estimate the function $f$ given a labeled training set, and then to make predictions on __new (outside of training set)__ using $\\hat{y}=\\hat{f}(\\mathbf{x})$\n",
    "\n",
    "This is called __generalization__.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Probabilistic view of supervised learning\n",
    "\n",
    "We can model a supervised learning problem as a conditional probability $p(y|\\mathbf{x},\\mathcal{D})$ on the __test__ input $\\mathbf{x}$ and the training set $\\mathcal{D}$. Given a probabilistic output, we can make predictions using:\n",
    "\n",
    "$$\\hat{y}=\\hat{f}(\\mathbf{x})=\\underset{c\\in{C}}{\\arg\\max}\\, {p}(y=c|\\mathbf{x},\\mathcal{D})$$\n",
    "\n",
    "This is called a __MAP estimate__ (MAP stands for maximum a posteriori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "Learn a mapping from inputs $\\mathbf{x}$ to outputs $y$, where\n",
    "$y\\in\\{1,...,C\\}$, with $C$ being the number of classes.\n",
    "\n",
    "If $C=2$, this is called __binary classification__ and it oftend assumed that $y\\in\\{0,1\\}$\n",
    "\n",
    "If $C>2$, this is called __multiclass classification__.\n",
    "\n",
    "If the class labels are not mutually exclusive this is called __multi-label classification__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unsupervised learning\n",
    "\n",
    "Given inputs, $\\mathcal{D}=\\{\\mathbf{x_i}\\}_{i=1}^N$, find \"patterns\", \"structure\", or other insights in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning\n",
    "\n",
    "\n",
    "Learn how to act or behave when given occasional reward or punishment signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic concepts in machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
