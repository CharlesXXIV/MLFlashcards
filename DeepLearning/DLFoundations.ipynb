{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Foundations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is deep learning?\n",
    "\n",
    "\n",
    "![Deep Learning](images/dl.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why deep representation?\n",
    "\n",
    "Circuit theory proves that there are functions that can be computed with \"narrow\" (relatively small number of hidden units in a layer) but deep (many layers) that shallower networks require exponentially more hidden units to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural networks as computational graphs\n",
    "\n",
    "![Computational graphs](images/graphs.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural network training\n",
    "\n",
    "![ANN training](images/training.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural network representation\n",
    "\n",
    "![Representation](images/representation.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural network representation - vector notation\n",
    "\n",
    "![Representation](images/representation2.PNG)\n",
    "\n",
    "Let\n",
    "\n",
    "$\\mathbf X =\\begin{bmatrix} | & | &   & | \\\\ \n",
    "                \\mathbf x^{(1)} & \\mathbf x^{(2)} & \\cdots & \\mathbf x^{(m)} \\\\\n",
    "                          | & | &   & | \\end{bmatrix},\\qquad$\n",
    "$\\mathbf x^{(i)} = \\begin{bmatrix} x_1^{(i)} \\\\ x_2^{(i)} \\\\ \\vdots \\\\ x_{n^{[0]}}^{(i)} \\end{bmatrix},\\qquad$\n",
    "$\\mathbf X\\in\\mathbb R^{n^{[0]} \\times m},\\qquad$\n",
    "$\\mathbf x\\in\\mathbb R^{n^{[0]}}$\n",
    "\n",
    "$\\mathbf A^{[l]}=\\begin{bmatrix} | & | &   & | \\\\ \n",
    "                \\mathbf a^{[l](1)} & \\mathbf a^{[l](2)} & \\cdots & \\mathbf a^{[l](m)} \\\\\n",
    "                          | & | &   & | \\end{bmatrix},\\qquad$\n",
    "$\\mathbf a^{[l](i)} = \\begin{bmatrix} a_1^{[l](i)} \\\\ a_2^{[l](i)} \\\\ \\vdots \\\\ a_{n^{[l]}}^{[l](i)} \\end{bmatrix},\\qquad$       $\\mathbf A\\in\\mathbb R^{n^{[l]} \\times m},\\qquad$\n",
    "$\\mathbf a\\in\\mathbb R^{n^{[l]}}$           \n",
    "                          \n",
    "$\\mathbf W^{[l]}=\\begin{bmatrix} -\\mathbf w_{1}^{[l]}- \\\\ \n",
    "                                 -\\mathbf w_{2}^{[l]}- \\\\ \n",
    "                                 \\vdots \\\\ \n",
    "                                 -\\mathbf w_{n^{[l]}}^{[l]}- \\\\ \n",
    "                 \\end{bmatrix},\\qquad$\n",
    "$\\mathbf w_{i}^{[l]}=[w_1^{[l]},w_2^{[l]}, \\cdots, w_{n^{[l-1]}}^{[l]}],\\qquad$\n",
    "$\\mathbf b^{[l]}=\\begin{bmatrix} b_{1}^{[l]} \\\\ \n",
    "                                 b_{2}^{[l]} \\\\ \n",
    "                                 \\vdots \\\\ \n",
    "                                 b_{n^{[l]}}^{[l]} \\\\ \n",
    "                 \\end{bmatrix},\\qquad$ \n",
    "$\\mathbf W\\in\\mathbb R^{n^{[l]} \\times n^{[l-1]}},\\qquad$\n",
    "$\\mathbf b\\in\\mathbb R^{n^{[l]}}$   \n",
    "                          \n",
    "then               \n",
    "\n",
    "$\\mathbf Z^{[1]}=\\mathbf W^{[1]}\\mathbf X + \\mathbf b^{[1]},\\qquad$\n",
    "$\\mathbf A^{[1]}=\\sigma(\\mathbf Z^{[1]})$\n",
    "\n",
    "$\\mathbf Z^{[2]}=\\mathbf W^{[2]}\\mathbf A^{[1]} + \\mathbf b^{[2]},\\qquad$\n",
    "$\\mathbf A^{[2]}=\\sigma(\\mathbf Z^{[2]})$\n",
    "\n",
    "$\\mathbf Z^{[l]}=\\mathbf W^{[l]}\\mathbf A^{[l-1]} + \\mathbf b^{[l]},\\qquad$\n",
    "$\\mathbf A^{[l]}=\\sigma(\\mathbf Z^{[l]})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activation functions\n",
    "\n",
    "\n",
    "![Activation functions](images/activations.PNG)\n",
    "\n",
    "$\\qquad\\qquad a=\\dfrac{1}{1+e^{-z}}\\qquad\\qquad\\qquad\\qquad\\qquad$\n",
    "$a=\\dfrac{e^z-e^{-z}}{e^z+e^{-z}}\\qquad\\qquad\\qquad\\qquad$\n",
    "$a=\\max(0,z)\\qquad\\qquad\\qquad\\qquad$\n",
    "$a=\\max(\\alpha z,z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Output units\n",
    "\n",
    "Let's assume that the hidden layers compute a set of hidden features defined by\n",
    "\n",
    "$\\mathbf h=f(\\mathbf x; \\boldsymbol \\Theta),\\qquad$where $\\boldsymbol \\Theta$ is a set of all parameter tensors in hidden layers $\\boldsymbol \\Theta=\\{\\mathbf W^{[1]},...,\\mathbf W^{[L_h]},\\mathbf b^{[1]},...,\\mathbf b^{[L_h]}\\}$\n",
    "\n",
    "The role of the ouput layer is then to provide some additional transformation from the features to complete the task that the network must perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear units\n",
    "\n",
    "Given features $\\mathbf h$, a layer linear output units produces a vector\n",
    "\n",
    "$\\hat y=\\mathbf W^T\\mathbf h + \\mathbf b, \\quad$ where $\\mathbf W, \\mathbf b$ are parameter tensors of the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sigmoid units for binary classification tasks\n",
    "\n",
    "In the case of binary classification the output layer comprises a single unit.\n",
    "\n",
    "Given features $\\mathbf h$, a sigmoid output unit produces a scalar value that can be interpreted as a probability of a positive class. \n",
    "\n",
    "$\\hat y=\\sigma(\\mathbf w^T\\mathbf h + \\mathbf b), \\quad$ where $\\mathbf w, \\mathbf b$ are parameter vectors of the output unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Softmax units for multiclass classification tasks\n",
    "\n",
    "\n",
    "Given features $\\mathbf h$, a softmax output layer produces a vector $\\hat{\\mathbf y}$ that can be interpreted as the probablity distribution over $k$ different classes. \n",
    "\n",
    "Let\n",
    "\n",
    "$\\mathbf z = \\mathbf W^T\\mathbf h+\\mathbf b, \\quad$ where $\\mathbf W, \\mathbf b$ are parameter tensors of the output layer.\n",
    "\n",
    "$\\hat{y_i}=softmax(\\mathbf z)_i=\\dfrac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}, \\quad$ where $\\mathbf w, \\mathbf b$ are parameter vectors of the output unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other output types\n",
    "\n",
    "The linear, sigmoid, and softmax output units are the most common. However; neural networks can generalize to almost any kind of output layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cost functions\n",
    "\n",
    "An important aspect of the design of a deep neural network is the choice of the cost function. The cost functions for neural networks are more or less the same as those for other parametric models.\n",
    "\n",
    "Most modern neural networks are trained using maximum likelihood. This meand that the cost function is simply the negative log-ikelihood, equivalenty described as the cross-entropy between the training data and the model distribution.\n",
    "\n",
    "$J(\\boldsymbol \\Theta)=-\\mathbb E_{\\mathbf x, \\mathbf y \\sim \\hat p_{data}} \\log p_{model}(\\mathbf y|\\mathbf x)$\n",
    "\n",
    "The specific form of the cost function depends on the form of $\\log p_{model}$ and as such on the type of units used in the output layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross-entropy cost for binary classification\n",
    "\n",
    "Let $\\mathcal D=\\{(\\mathbf x^{(1)},y^{(1)}),...,(\\mathbf x^{(m)},y^{(m)})\\}$ be a training data set and $\\hat y(\\mathbf x)$ the ouput of the network.\n",
    "\n",
    "\n",
    "$J(\\boldsymbol \\Theta)=-\\dfrac{1}{m}\\sum_{i=1}^m(y^{(i)} \\log(\\hat y^{(i)}) + (1-y^{(i)}) \\log (1-\\hat y^{(i)}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross-entropy cost for multiclass classification\n",
    "\n",
    "Let $\\mathcal D=\\{(\\mathbf x^{(1)}, \\mathbf y^{(1)}),...,(\\mathbf x^{(m)}, \\mathbf y^{(m)})\\}$ be a training data set and $\\hat {\\mathbf y(\\mathbf x)}$ the ouput of the network.\n",
    "\n",
    "\n",
    "$J(\\boldsymbol \\Theta)=-\\dfrac{1}{m}\\sum_{i=1}^m \\sum_{k=1}^C y_k^{(i)} \\log(\\hat y_k^{(i)}),\\quad $ where $C$ is the number of classes (the size of the output vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "To make it easier to understand, the following description shows how to calculate the gradient on a single training tuple $(\\mathbf x, \\mathbf y)$. In practice, backpropagation is vectorized and calculations are done on a whole minibatch. \n",
    "\n",
    "\n",
    "1.__Set the activations for the input layer__ $l=0$\n",
    "\n",
    "$\\qquad \\mathbf a^{[0]}=\\mathbf x$\n",
    "\n",
    "2.__Feedforward__: For each layer $l=1,2,...,L$: compute and cache:\n",
    "\n",
    "$\\qquad \\mathbf z^{[l]}=\\mathbf W^{[l]}\\mathbf a^{[l-1]}+\\mathbf b^{[l]},\\,$ and $\\mathbf a^{[l]}=\\sigma(\\mathbf z^{[l]})$\n",
    "\n",
    "3.__Compute the output error__ $\\boldsymbol \\delta^L$: \n",
    "\n",
    "$\\qquad \\boldsymbol \\delta^L = \\nabla_a J \\odot \\sigma^{'}(\\mathbf z^L)$\n",
    "\n",
    "4.__Backpropagate the error__: For each layer $l=L-1,L-2,...,1$ compute:\n",
    "\n",
    "$\\qquad \\boldsymbol \\delta^l = ((\\mathbf W^{l+1})^T \\boldsymbol \\delta^{l+1}) \\odot \\boldsymbol \\delta^{'} (\\mathbf z^l)$\n",
    "\n",
    "5.__Calculate gradient__:\n",
    "\n",
    "$\\qquad \\dfrac{\\partial J}{w_{ij}^l}=a_j^{[l-1]}\\delta_i^l\\quad$ and $\\dfrac{\\partial J}{b_{i}^l}=\\delta_i^l$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Derivates of activaton functions\n",
    "\n",
    "__Sigmoid__\n",
    "\n",
    "\n",
    "\n",
    "$g(z)=\\dfrac{1}{1+e^{-z}} \\quad \\Longrightarrow \\quad \\dfrac{d}{dz}g(z)=g(z)(1-g(z))$\n",
    "\n",
    "$g(z)=\\dfrac{e^{z}-e^{-z}}{e^{z}+e^{-z}} \\quad \\Longrightarrow \\quad \\dfrac{d}{dz}g(z)=1-(g(z))^2$\n",
    "\n",
    "$g(z)=\\max(0,z) \\quad \\Longrightarrow \\quad \\dfrac{d}{dz}g(z)=\\left\\{ \\begin{array}{} 0\\, if\\, z \\lt 0 \\\\ 1\\, if\\, z \\geq 0 \\end{array}\\right., \\qquad$ Technically $\\dfrac{d}{dz}g(z)$ is not defined at 0 but in practice it can be \"overlooked\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularization\n",
    "\n",
    "-  Parameter Norm Penalties\n",
    "-  Dropout\n",
    "-  Data augmentation\n",
    "-  Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter norm penalties\n",
    "\n",
    "Let $\\mathcal D=\\{(\\mathbf x^{(1)}, \\mathbf y^{(1)}),...,(\\mathbf x^{(m)}, \\mathbf y^{(m)})\\}$ be a training data set, $\\hat {\\mathbf y(\\mathbf x)}$ the ouput of the network, and $\\Theta$ a set of all parameter tensors in the network $\\boldsymbol \\Theta=\\{\\mathbf W^{[1]},...,\\mathbf W^{[L]},\\mathbf b^{[1]},...,\\mathbf b^{[L]}\\}$.\n",
    "\n",
    "The unregularized cost function is defined as:\n",
    "\n",
    "$J(\\boldsymbol \\Theta)=\\sum_{i=1}^m \\mathcal L (\\hat{\\mathbf y}^{(i)}, \\mathbf y^{(i)}),\\quad$ where $\\mathcal L$ is a per sample loss.\n",
    "\n",
    "We can regularize the cost function by adding the penalty term:\n",
    "\n",
    "$J_{reg}(\\boldsymbol \\Theta)=\\sum_{i=1}^m \\mathcal L (\\hat{\\mathbf y}^{(i)}, \\mathbf y^{(i)}) + \\alpha \\Omega(\\boldsymbol \\Theta)\\quad$ where $\\alpha \\in [0,\\infty]$ is a hyperparameter that weights the relative contribution of the penalty term $\\Omega$.\n",
    "\n",
    "The $L^2$ regularization is the most common parameter norm penalty.\n",
    "\n",
    "$J_{reg}(\\boldsymbol \\Theta)=\\sum_{i=1}^m \\mathcal L (\\hat{\\mathbf y}^{(i)}, \\mathbf y^{(i)}) + \\dfrac{\\lambda}{2m}\\sum_{l=1}^L \\Vert \\mathbf W^{[l]} \\Vert_F^2$\n",
    "\n",
    "Where $\\Vert \\mathbf W^{[l]} \\Vert_F^2=\\sum_{i=1}^{n^{[l]}} \\sum_{j=1}^{n^{[l-1]}}(w_{ij}^{[l]})^2\\,$ is a __Frobenius norm__ of $\\mathbf W^{[l]}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropout\n",
    "\n",
    "__Dropout__ provides a computationally inexpensive but powerful method of regularizing a broad family of models.\n",
    "\n",
    "![Dropout](images/dropout.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalizing training sets\n",
    "\n",
    "Let $\\mathbf X=\\{\\mathbf x^{(1)},...,\\mathbf x^{(m)}\\}$ be a training data set where $\\mathbf x=\\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n\\end{bmatrix}$\n",
    "\n",
    "The most common normalization technique is standarization:\n",
    "\n",
    "$ x_i^{'}=\\dfrac{x_i - \\mu_i}{\\sigma_i^2}\\quad$ where $\\mu_i=\\dfrac{1}{m}\\sum_{j=1}^{m}x_i^{(j)}\\quad$ and $\\sigma_i^2=\\dfrac{1}{m}\\sum_{j=1}^{m}(x_i^{(j)} - \\mu_i)^2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization algorithms\n",
    "\n",
    "1. Mini-batch gradient descent\n",
    "2. Gradient descent with momentum\n",
    "3. RMSProp\n",
    "4. ADAM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mini-batch gradient descent\n",
    "\n",
    "To simplify the notation, the following formulas show how to update a single parameter tensor. When  working with sets of parameter tensors the same logic is applied to each tensor.\n",
    "\n",
    "On each iteration:\n",
    "\n",
    "$\\qquad$ Compute gradients $\\nabla J(\\boldsymbol \\Theta)$ on a current minibatch\n",
    "\n",
    "$\\qquad$ Update the parameters using the following formulas: \n",
    "\n",
    "$\\qquad\\qquad \\boldsymbol \\Theta \\leftarrow \\boldsymbol \\Theta - \\alpha \\nabla J(\\boldsymbol \\Theta)$\n",
    "\n",
    "$\\alpha$ - learning rate - is a hyperparameter of gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent with momentum\n",
    "\n",
    "To simplify the notation, the following formulas show how to update a single parameter tensor. When  working with sets of parameter tensors the same logic is applied to each tensor.\n",
    "\n",
    "Initialize $\\mathbf v_{\\boldsymbol \\Theta}$ with zeros\n",
    "\n",
    "On each iteration:\n",
    "\n",
    "$\\qquad$ Compute gradients $\\nabla J(\\Theta)$ on a current minibatch\n",
    "\n",
    "$\\qquad$ Update the parameters using the following formulas:\n",
    "\n",
    "$\\qquad\\qquad \\mathbf v_{\\boldsymbol \\Theta}= \\beta \\mathbf v_{\\boldsymbol \\Theta} + (1-\\beta)\\nabla J(\\Theta)$\n",
    "\n",
    "$\\qquad\\qquad \\mathbf{\\boldsymbol \\Theta}= \\boldsymbol{\\Theta} - \\alpha \\mathbf v_{\\boldsymbol \\Theta}$\n",
    "\n",
    "\n",
    "$\\alpha$ and $\\beta$ are hyperparameters. \n",
    "\n",
    "\n",
    "$\\alpha$ needs to be tuned.\n",
    "\n",
    "$\\beta$ is usually set to $0.9$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RMSprop (Root Mean Square prop)\n",
    "\n",
    "To simplify the notation, the following formulas show how to update a single parameter tensor. When  working with sets of parameter tensors the same logic is applied to each tensor.\n",
    "\n",
    "Initialize $\\mathbf s_{\\boldsymbol \\Theta}$ with zeros\n",
    "\n",
    "On each iteration:\n",
    "\n",
    "\n",
    "$\\qquad$ Compute gradients $\\nabla J(\\Theta)$ on a current minibatch\n",
    "\n",
    "$\\qquad$ Update the parameters using the following formulas:\n",
    "\n",
    "$\\qquad\\qquad \\mathbf s_{\\boldsymbol \\Theta}= \\beta \\mathbf s_{\\boldsymbol \\Theta} + (1-\\beta)(\\nabla J(\\Theta))^2$\n",
    "\n",
    "$\\qquad\\qquad \\mathbf{\\boldsymbol \\Theta}= \\boldsymbol{\\Theta} - \\alpha \\dfrac{\\nabla J(\\Theta)}{\\sqrt{\\mathbf S_{\\boldsymbol \\Theta}}+\\epsilon}\\quad$ where $\\epsilon$ is a small number added for numerical stability. Usually $\\epsilon=10^{-8}$\n",
    "\n",
    "\n",
    "$\\alpha$ and $\\beta$ are hyperparameters. \n",
    "\n",
    "$\\alpha$ needs to be tuned\n",
    "\n",
    "$\\beta$ is usually set to $0.9$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ADAM (Adaptive moment estimation)\n",
    "\n",
    "To simplify the notation, the following formulas show how to update a single parameter tensor. When  working with sets of parameter tensors the same logic is applied to each tensor.\n",
    "\n",
    "Initialize $\\mathbf v_{\\boldsymbol \\Theta}$ and $\\mathbf s_{\\boldsymbol \\Theta}$with zeros\n",
    "\n",
    "On each iteration $t$:\n",
    "\n",
    "$\\qquad$ Compute gradients $\\nabla J(\\Theta)$ on a current minibatch\n",
    "\n",
    "$\\qquad$ Update the parameters using the following formulas:\n",
    "\n",
    "$\\qquad\\qquad \\mathbf v_{\\boldsymbol \\Theta}= \\beta_1 \\mathbf v_{\\boldsymbol \\Theta} + (1-\\beta_1)\\nabla J(\\Theta)$\n",
    "\n",
    "$\\qquad\\qquad \\mathbf v_{\\boldsymbol \\Theta}^{corrected}= \\dfrac{\\mathbf v_{\\boldsymbol \\Theta}}{1-\\beta_1^t}$\n",
    "\n",
    "$\\qquad\\qquad \\mathbf s_{\\boldsymbol \\Theta}= \\beta_2 \\mathbf s_{\\boldsymbol \\Theta} + (1-\\beta_2)(\\nabla J(\\Theta))^2$\n",
    "\n",
    "$\\qquad\\qquad \\mathbf s_{\\boldsymbol \\Theta}^{corrected}= \\dfrac{s_{\\boldsymbol \\Theta}}{1-\\beta_2^t}$\n",
    "\n",
    "$\\qquad\\qquad \\mathbf{\\boldsymbol \\Theta}= \\boldsymbol{\\Theta} - \\alpha \\dfrac{\\mathbf v_{\\boldsymbol \\Theta}^{corrected}}{\\sqrt{\\mathbf s_{\\boldsymbol \\Theta}^{corrected}} +\\epsilon}\\quad$ where $\\epsilon$ is a small number added for numerical stability. Usually $\\epsilon=10^{-8}$\n",
    "\n",
    "\n",
    "$\\alpha$ and $\\beta_1$ $\\beta_2$ are hyperparameters \n",
    "\n",
    "$\\alpha$ needs to be tuned\n",
    "\n",
    "$\\beta_1$ is usually set to $0.9$\n",
    "\n",
    "$\\beta_2$ is usually set to $0.999$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning rate decay\n",
    "\n",
    "As we approach the minimum during optimization it is beneficial to gradually decrease the leraning rate $\\alpha$.\n",
    "\n",
    "There are many formulas that can be used to implement the learning rate decay.\n",
    "\n",
    "Let $j$ be the current epoch number and $\\alpha_j$ the learning rate to be used at the epoch $j$, $\\alpha_0$ be the initial learning rate, and $\\lambda$ be a decay rate.\n",
    "\n",
    "$\\alpha_j=\\dfrac{1}{1+ j\\lambda }\\alpha_0$\n",
    "\n",
    "$\\alpha_j=a^{j}\\alpha_0\\quad$ where $a$ is a constant close to $0$\n",
    "\n",
    "$\\alpha_j=\\dfrac{k}{\\sqrt i}\\alpha_0\\quad$ where $k$ is an arbitrary constant\n",
    "\n",
    "$Discrete \"staircase\" learning rate$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
